{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "save_model&tokenaizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5KemCZJ7-MY"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twgxkZA78Odu"
      },
      "source": [
        "from transformers import (T5ForConditionalGeneration,\n",
        "                          AdamW,\n",
        "                          T5TokenizerFast as token)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufQSi-fF8UWe"
      },
      "source": [
        "BATCH = 1\n",
        "EPOCHS =1\n",
        "\n",
        "config={\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"architecture\": \"T5\",\n",
        "    'model': 't5-small',# 't5-base',\n",
        "    \"dataset\": \"Coleridge Initiative \",\n",
        "    'tex_max_len': 396,\n",
        "    'asw_max_len': 12,\n",
        "    'batch_size' : BATCH,\n",
        "    'epoch':EPOCHS,\n",
        "    'device': 'cuda'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOY5FGtu89sl"
      },
      "source": [
        "[link](https://huggingface.co/transformers/model_sharing.html)\n",
        "\n",
        "It should only have:\n",
        "\n",
        "- a config.json file, which saves the configuration of your model ;\n",
        "- a pytorch_model.bin file, which is the PyTorch checkpoint (unless you canâ€™t have it for some reason) ;\n",
        "- a special_tokens_map.json, which is part of your tokenizer save;\n",
        "- a tokenizer_config.json, which is part of your tokenizer save;\n",
        "- files named vocab.json, vocab.txt, merges.txt, or similar, which contain the vocabulary of your tokenizer, part of your tokenizer save;\n",
        "- maybe a added_tokens.json, which is part of your tokenizer save.\n",
        "\n",
        "Other files can safely be deleted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVzqAENX8vSW"
      },
      "source": [
        "# save token\n",
        "tokenizer.save_pretrained(\"./model_small_t5\")\n",
        "#save model\n",
        "model = T5ForConditionalGeneration.from_pretrained(config['model'])\n",
        "model.save_pretrained(\"./model_small\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}