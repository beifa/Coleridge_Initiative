{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "infernce_t5_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 229.47705,
      "end_time": "2021-06-11T08:38:39.973279",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-06-11T08:34:50.496229",
      "version": "2.2.2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8CCmQ-bLhgv"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY_c2kWfE1S6"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install pytorch_lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "304fvKEpCdx7",
        "outputId": "d3e3a4c5-d574-4301-fc6a-1c23018405ab"
      },
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os, glob, re, gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import permutations \n",
        "from collections import defaultdict\n",
        "from transformers import (T5ForConditionalGeneration,\n",
        "                          AdamW,\n",
        "                          T5TokenizerFast as token)\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "pl.seed_everything(13)\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 13\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1_fSQqWCdyD"
      },
      "source": [
        "def clean_text(txt):\n",
        "    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower()).strip()\n",
        "\n",
        "def clean_text_dig(txt):\n",
        "    return re.sub('[^A-Za-z]+', ' ', str(txt).lower()).strip()\n",
        "\n",
        "def find_start(title, text):\n",
        "    start = re.search(r'\\b%s\\b' % title, text)\n",
        "    if start == None:\n",
        "        start = 0\n",
        "    else:\n",
        "        start = start.start()\n",
        "    return start\n",
        "\n",
        "def jaccard(str1, str2): \n",
        "    a = set(str1.lower().split()) \n",
        "    b = set(str2.lower().split())\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
        "\n",
        "def totally_clean_text(txt):\n",
        "    txt = clean_text(txt)\n",
        "    txt = re.sub(' +', ' ', txt)\n",
        "    return txt\n",
        "\n",
        "def make_interval(start:int, txt:str, interval: int)->str:\n",
        "    \"\"\"\n",
        "    start: int return re.search() count latter\n",
        "    txt: str text\n",
        "    interval: int len text \n",
        "\n",
        "    return: str text\n",
        "    \"\"\"\n",
        "    words = txt.split()\n",
        "    len_interval = interval * 2\n",
        "    start = len(txt[:start].split())    \n",
        "    if (start - interval) > 0:\n",
        "        start = start - interval\n",
        "        if start + len_interval < len(words):\n",
        "            words = words[start: start + len_interval]\n",
        "        else:              \n",
        "            words = words[start: len(words)]\n",
        "    else:      \n",
        "        words = words[0: len_interval]\n",
        "    return ' '.join(words)\n",
        "\n",
        "def count_answer(df: pd.DataFrame)-> dict:\n",
        "    df['len_title'] = df.section_title.apply(lambda x: len(x.split()))\n",
        "    #need more clear title skip error\n",
        "    qwest = df[df.len_title >= 4].section_title.values\n",
        "    txt = df.text.str.cat()\n",
        "    txt = clean_text(txt)\n",
        "    tmp = {}\n",
        "    for qw in qwest:\n",
        "        qw = clean_text_dig(qw)  \n",
        "        if qw in txt:\n",
        "            start = find_start(qw, txt)\n",
        "            tmp['section_title'] = qw  \n",
        "            tmp['text'] = make_interval(start, txt, 396)\n",
        "    return tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbKkzpViMRPd"
      },
      "source": [
        "PATH_ORI_TRAIN = '/content/drive/MyDrive/Coleridge_Initiative/input/train.csv'\n",
        "PATH_ORI_JSON = '/content/drive/MyDrive/Coleridge_Initiative/input/train'\n",
        "PATH_ORI_JSON_TEST = '/content/drive/MyDrive/Coleridge_Initiative/input/test'\n",
        "PATH_SUB = '/content/drive/MyDrive/Coleridge_Initiative/input/sample_submission.csv'\n",
        "train = pd.read_csv(PATH_ORI_TRAIN)\n",
        "sub = pd.read_csv(PATH_SUB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "snZvpSOKNOMo",
        "outputId": "cd4c5eb6-dc08-499a-fcff-923ce148733f"
      },
      "source": [
        "papers = {}\n",
        "for json_id in tqdm(train['Id'].unique()):\n",
        "    with Path(PATH_ORI_JSON, json_id + '.json').open('r') as jsn:\n",
        "        cur_jsn = json.load(jsn)\n",
        "        tmp_df = pd.DataFrame(cur_jsn)\n",
        "        dct = count_answer(tmp_df)\n",
        "        if len(dct) > 0:\n",
        "            papers[paper_id] = [dct]\n",
        "            \n",
        "len(papers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14316/14316 [1:04:28<00:00,  3.70it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMxHvk8ZCdyF",
        "outputId": "2b50decb-ef03-48c9-baf5-423a9b7c0e4c"
      },
      "source": [
        "for paper_id in sub['Id']:\n",
        "    with Path(PATH_ORI_JSON_TEST, json_id + '.json').open('r') as jsn:\n",
        "        paper = json.load(f)\n",
        "        tmp_df = pd.DataFrame(paper)\n",
        "        dct = count_answer(tmp_df)\n",
        "        papers[paper_id] = [dct]\n",
        "\n",
        "len(papers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5391"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amv8APXcCdyH"
      },
      "source": [
        "# def count_answer(df: pd.DataFrame):\n",
        "#     df['len_title'] = df.section_title.apply(lambda x: len(x.split()))\n",
        "#     #need more clear title skip error\n",
        "#     qwest = df[df.len_title >= 4].section_title.values\n",
        "#     txt = df.text.str.cat()\n",
        "#     txt = clean_text(txt)\n",
        "#     count = 0\n",
        "#     for qw in qwest:\n",
        "#         qw = clean_text_dig(qw)    \n",
        "#         if qw in txt:\n",
        "#             count += 1\n",
        "#     return count\n",
        "\n",
        "# tmp = {}\n",
        "# for k in tqdm(papers.keys()):\n",
        "#     df = pd.DataFrame(papers[str(k)])\n",
        "#     count = count_answer(df)\n",
        "#     if count >= 0:\n",
        "#         tmp[str(k)] = count  \n",
        "\n",
        "# count_zero = 0\n",
        "# count_not = 0\n",
        "# for k,v in tmp.items():\n",
        "#     if v == 0:\n",
        "#         count_zero += 1\n",
        "#     else:\n",
        "#         count_not += 1\n",
        "# print(count_zero, count_not)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoiWmUAbCdyI",
        "outputId": "56c9b98c-5948-4d18-80f1-f606c12a8516"
      },
      "source": [
        "all_labels = set()\n",
        "\n",
        "for label_1, label_2, label_3 in train[['dataset_title', 'dataset_label', 'cleaned_label']].itertuples(index=False):\n",
        "    all_labels.add(str(label_1).lower())\n",
        "    all_labels.add(str(label_2).lower())\n",
        "    all_labels.add(str(label_3).lower())\n",
        "\n",
        "print(f'No. different labels: {len(all_labels)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. different labels: 180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQVOQHxaCdyJ",
        "outputId": "f999c71b-df91-4d67-dabd-7358d891e218"
      },
      "source": [
        "papers2 = {}\n",
        "for paper_id in train['Id'].unique():\n",
        "    with Path(PATH_ORI_JSON, json_id + '.json').open('r') as jsn:\n",
        "        paper = json.load(jsn)\n",
        "        papers2[paper_id] = paper\n",
        "\n",
        "\n",
        "for paper_id in sample_submission['Id']:\n",
        "    with Path(PATH_ORI_JSON_TEST, json_id + '.json').open('r') as jsn:\n",
        "        paper = json.load(jsn)\n",
        "        papers2[paper_id] = paper\n",
        "        \n",
        "len(papers2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14316"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13PeVhy1CdyK"
      },
      "source": [
        "literal_preds = []\n",
        "\n",
        "for paper_id in sample_submission['Id']:\n",
        "    paper = papers2[paper_id]\n",
        "    text_1 = '. '.join(section['text'] for section in paper).lower()\n",
        "    text_2 = totally_clean_text(text_1)\n",
        "    \n",
        "    labels = set()\n",
        "    for label in all_labels:\n",
        "        if label in text_1 or label in text_2:\n",
        "            labels.add(clean_text(label))\n",
        "    \n",
        "    literal_preds.append('|'.join(labels))\n",
        "\n",
        "literal_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOG_Sv4FCdyK"
      },
      "source": [
        "BATCH = 3\n",
        "EPOCHS =1\n",
        "\n",
        "config={\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"architecture\": \"T5\",\n",
        "    'model': 't5-small',# 't5-base',\n",
        "    \"dataset\": \"Coleridge Initiative \",\n",
        "    'tex_max_len': 396,\n",
        "    'asw_max_len': 12,\n",
        "    'batch_size' : BATCH,\n",
        "    'epoch':EPOCHS,\n",
        "    'device': 'cuda'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QOWMXp_CdyL"
      },
      "source": [
        "class CI(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained('../input/ci-model-small/model', return_dict = True)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels):\n",
        "        out = self.model(input_ids = input_ids,\n",
        "                    attention_mask = attention_mask,\n",
        "                    labels = labels\n",
        "                    )\n",
        "        return out.loss, out.logits\n",
        "\n",
        "\n",
        "def make_pred(question:str, pre_model, tokenizer)->str:\n",
        "    encode_test = tokenizer(question['question'],\n",
        "                        question['text'],    \n",
        "                        max_length = 396, \n",
        "                        padding= 'max_length',\n",
        "                        truncation = False,#'only_second',\n",
        "                        return_attention_mask = True,\n",
        "                        add_special_tokens =True,\n",
        "                        return_tensors = 'pt'\n",
        "                        )\n",
        "    gen_ids = pre_model.model.generate(\n",
        "        input_ids = encode_test['input_ids'],\n",
        "        attention_mask = encode_test['attention_mask'],\n",
        "        num_beams = 5,\n",
        "        no_repeat_ngram_size = 1,            \n",
        "        num_return_sequences = 1,     \n",
        "        do_sample=True,      \n",
        "        top_k=0,\n",
        "        top_p=0.92,       \n",
        "        max_length = 8,\n",
        "        repetition_penalty = 2.5,\n",
        "        length_penalty =0.5,               \n",
        "        early_stopping = True,\n",
        "        use_cache = True\n",
        "        )\n",
        "\n",
        "\n",
        "    decode = [\n",
        "              tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "              for ids in gen_ids\n",
        "              ]\n",
        "    return ' '.join(decode)\n",
        "    \n",
        "\n",
        "def make_interval(start:int, txt:str, interval: int)->str:\n",
        "    \"\"\"\n",
        "    start: int return re.search() count latter\n",
        "    txt: str text\n",
        "    interval: int len text \n",
        "\n",
        "    return: str text\n",
        "    \"\"\"\n",
        "    words = txt.split()\n",
        "    len_interval = interval * 2\n",
        "    start = len(txt[:start].split())    \n",
        "    if (start - interval) > 0:\n",
        "        start = start - interval\n",
        "        if start + len_interval < len(words):\n",
        "            words = words[start: start + len_interval]\n",
        "        else:              \n",
        "            words = words[start: len(words)]\n",
        "    else:      \n",
        "        words = words[0: len_interval]\n",
        "    return ' '.join(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-GTO5s8CdyM"
      },
      "source": [
        "\"\"\"\n",
        "{'d0fa7568-7d8e-4db9-870f-f9c6f668c17b': [\n",
        "        {'section_title': 'What is this study about?',\n",
        "        'text': 'This study used data from the National Education Longitudinal Study (NELS:88)...\n",
        "        }],\n",
        "},\n",
        "\"\"\"\n",
        "def makedata(title, text, model, tokenizer, skip_title = True):\n",
        "    data = {'question':title,\n",
        "            'text': text,\n",
        "           }  \n",
        "    y_ = make_pred(data, model, tokenizer)\n",
        "    y_ = clean_text(y_)\n",
        "    return y_\n",
        "\n",
        "\n",
        "model = CI(config)\n",
        "MODEL = config['model']\n",
        "model.load_state_dict(torch.load('../input/ci-model-small/model_check_predict_small.pth'))\n",
        "model.eval()\n",
        "tokenizer = token.from_pretrained('../input/ci-model-small/token')\n",
        "labels = []\n",
        "for paper_id in sample_submission['Id']:\n",
        "    paper = papers[paper_id]  \n",
        "    label = []\n",
        "    for dct in paper:\n",
        "        if len(dct) > 0:\n",
        "            title = dct['section_title']\n",
        "            txt = dct['text']\n",
        "            if (title  != '') and (txt  != ''):\n",
        "                y_ = makedata(title, txt, model, tokenizer)        \n",
        "            else:\n",
        "                y_ = ''\n",
        "        else: y_ = ''\n",
        "        if y_ != '': label.append(y_)\n",
        "        gc.collect()\n",
        "    labels.append(np.unique(label))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWyCQqscCdyN",
        "outputId": "ec304d3b-3dac-4961-c7c6-e23b546b0d7b"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([], dtype=float64),\n",
              " array(['isced97 level'], dtype='<U13'),\n",
              " array(['and ocraco'], dtype='<U10'),\n",
              " array([], dtype=float64)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Otq2hwz4CdyP"
      },
      "source": [
        "def jaccard_similarity(s1, s2):\n",
        "    l1 = s1.split(\" \")\n",
        "    l2 = s2.split(\" \")    \n",
        "    intersection = len(list(set(l1).intersection(l2)))\n",
        "    union = (len(l1) + len(l2)) - intersection\n",
        "    return float(intersection) / union\n",
        "\n",
        "filtered_bert_labels = []\n",
        "\n",
        "for lab in labels:\n",
        "    filtered = []\n",
        "    \n",
        "    for label in sorted(lab, key=len):\n",
        "  \n",
        "        label = clean_text(label)\n",
        "        if len(filtered) == 0 or all(jaccard_similarity(label, got_label) < 0.75 for got_label in filtered):\n",
        "            filtered.append(label)\n",
        "    \n",
        "    filtered_bert_labels.append('|'.join(filtered))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHMf-MD9CdyP",
        "outputId": "eb23f144-064f-4c9f-e94c-07d1ae6d8220"
      },
      "source": [
        "filtered_bert_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', 'isced97 level', 'and ocraco', '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrHAKXi2CdyQ"
      },
      "source": [
        "final_predictions = []\n",
        "for literal_match, bert_pred in zip(literal_preds, filtered_bert_labels):\n",
        "    if literal_match:\n",
        "        final_predictions.append(literal_match)\n",
        "    else:\n",
        "        final_predictions.append(bert_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RYdHVQBCdyQ",
        "outputId": "2762c4f6-a060-42e8-85f3-640e5dde17da"
      },
      "source": [
        "final_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alzheimer s disease neuroimaging initiative adni|adni',\n",
              " 'common core of data|nces common core of data|trends in international mathematics and science study',\n",
              " 'sea lake and overland surges from hurricanes|slosh model|noaa storm surge inundation',\n",
              " 'rural urban continuum codes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvX2Ga96CdyQ"
      },
      "source": [
        "sample_submission_path = '../input/coleridgeinitiative-show-us-the-data/sample_submission.csv'\n",
        "sample_submission = pd.read_csv(sample_submission_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNQ2fcl2CdyR"
      },
      "source": [
        "sample_submission['PredictionString'] = final_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUZ8BrWVCdyR",
        "outputId": "acc9f0e0-0e8e-4663-9cba-e8d52be1fda5"
      },
      "source": [
        "sample_submission.to_csv(f'submission.csv', index=False)\n",
        "sample_submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>PredictionString</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2100032a-7c33-4bff-97ef-690822c43466</td>\n",
              "      <td>alzheimer s disease neuroimaging initiative ad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2f392438-e215-4169-bebf-21ac4ff253e1</td>\n",
              "      <td>common core of data|nces common core of data|t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3f316b38-1a24-45a9-8d8c-4e05a42257c6</td>\n",
              "      <td>sea lake and overland surges from hurricanes|s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
              "      <td>rural urban continuum codes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     Id  \\\n",
              "0  2100032a-7c33-4bff-97ef-690822c43466   \n",
              "1  2f392438-e215-4169-bebf-21ac4ff253e1   \n",
              "2  3f316b38-1a24-45a9-8d8c-4e05a42257c6   \n",
              "3  8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
              "\n",
              "                                    PredictionString  \n",
              "0  alzheimer s disease neuroimaging initiative ad...  \n",
              "1  common core of data|nces common core of data|t...  \n",
              "2  sea lake and overland surges from hurricanes|s...  \n",
              "3                        rural urban continuum codes  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}