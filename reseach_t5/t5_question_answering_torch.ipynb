{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "t5_question_answering_torch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_3UZqLw61B9"
      },
      "source": [
        "!pip install pytorch_lightning\n",
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1Mu6OEa71I_"
      },
      "source": [
        "!pip install wandb -qqq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqC3b3SO8BeC"
      },
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqh7j3n878Id",
        "outputId": "b3a7f0d8-2df9-46cd-dc77-d79038866997"
      },
      "source": [
        "import json\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import os, glob, re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import (T5ForConditionalGeneration,\n",
        "                          AdamW,\n",
        "                          T5TokenizerFast as token)\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "from sklearn.model_selection import train_test_split\n",
        "pl.seed_everything(13)\n",
        "print(torch.__version__)\n",
        "PATH = '/content/drive/MyDrive/Coleridge_Initiative/input'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 13\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "id": "WY3lis9B9X5M",
        "outputId": "c50d631c-a75f-4191-9ad3-0dd24f5c5f12"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Coleridge_Initiative/input/v6_data_qa.csv')\n",
        "df[df.answer.isna()]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>text</th>\n",
              "      <th>answer</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer_end</th>\n",
              "      <th>origin_text</th>\n",
              "      <th>origin_answer_start</th>\n",
              "      <th>origin_answer_end</th>\n",
              "      <th>len text</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [question, text, answer, answer_start, answer_end, origin_text, origin_answer_start, origin_answer_end, len text, id]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skTdDeA19iuh"
      },
      "source": [
        "# wandb.init(project=\"ci\", config={\n",
        "#     \"learning_rate\": 0.0001,\n",
        "#     \"architecture\": \"T5\",\n",
        "#     'model': 't5-base',\n",
        "#     \"dataset\": \"Coleridge Initiative \",\n",
        "#     'tex_max_len': 396,\n",
        "#     'asw_max_len': 44,\n",
        "#     'batch_size' : BATCH_SIZE,\n",
        "#     'epoch':N_EPOCHS\n",
        "# })\n",
        "# config = wandb.config\n",
        "\n",
        "BATCH = 6\n",
        "EPOCHS =1\n",
        "\n",
        "config={\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"architecture\": \"T5\",\n",
        "    'model': 't5-base',\n",
        "    \"dataset\": \"Coleridge Initiative \",\n",
        "    'tex_max_len': 396,\n",
        "    'asw_max_len': 44,\n",
        "    'batch_size' : BATCH,\n",
        "    'epoch':EPOCHS,\n",
        "    'device': 'cuda'\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ceo8GpbU_Uuo"
      },
      "source": [
        "class CI_Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: pd.DataFrame,\n",
        "        tokenizer: token,\n",
        "        config\n",
        "    ):\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = data\n",
        "        self.tex_max_len = config['tex_max_len']\n",
        "        self.asw_max_len = config['asw_max_len']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index:int):\n",
        "        txt = self.data.iloc[index]\n",
        "\n",
        "        encode_txt = token(\n",
        "            txt['question'],\n",
        "            txt['text'],\n",
        "            max_length = self.tex_max_len, \n",
        "            padding= 'max_length',\n",
        "            truncation = 'only_second',\n",
        "            return_attention_mask = True,\n",
        "            add_special_tokens =True,\n",
        "            return_tensors = 'pt'\n",
        "            )\n",
        "        \n",
        "        encode_asw = token( \n",
        "            txt['answer'],\n",
        "            max_length = self.asw_max_len,\n",
        "            padding= 'max_length',\n",
        "            truncation = True,\n",
        "            return_attention_mask = True,\n",
        "            add_special_tokens =True,\n",
        "            return_tensors = 'pt'\n",
        "            )\n",
        "        labels = encode_asw['input_ids']\n",
        "        labels[labels == 0] = -100\n",
        "\n",
        "        return dict(\n",
        "            question=txt['question'],\n",
        "            text=txt['text'],\n",
        "            answer=txt['answer'],\n",
        "            input_ids=encode_txt['input_ids'].flatten(),\n",
        "            attention_mask=encode_txt['attention_mask'].flatten(),\n",
        "            labels = labels.flatten()\n",
        "            )\n",
        "        \n",
        "class CI(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(config['model'], return_dict = True)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels):\n",
        "        out = self.model(input_ids = input_ids,\n",
        "                    attention_mask = attention_mask,\n",
        "                    labels = labels\n",
        "                    )\n",
        "        return out.loss, out.logits"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBb9cgbwAC76",
        "outputId": "b2b7ac2c-f30c-42e9-ea9d-19955d0bb9fc"
      },
      "source": [
        "MODEL = config['model']\n",
        "token = token.from_pretrained(MODEL)\n",
        "exampe_dataset = CI_Dataset(df, token, config)\n",
        "\n",
        "for data in exampe_dataset:\n",
        "    print(data['question'])\n",
        "    print(data['text'])\n",
        "    print(data['answer'])\n",
        "\n",
        "    print(data['input_ids'][:10])\n",
        "    print(data['attention_mask'][:10])    \n",
        "    break"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the impact of evaluation use on accounting programs performance an exploratory study\n",
            "the quality of educational programs has been an object of debate and research around the world initiatives such as the program for international student assessment pisa and the trends in international mathematics and science study timss show that international organizations such as the organization for economic co operation and development oecd and the international association for the evaluation of educational achievement iea are trying to verify whether schools are adequately preparing their students by comparing their performances aiming to highlight the strengths and weaknesses among the educational systems of different countries higher education has also been the object of quality evaluations around the world ursin huusko aittola kiviniemi muhonen van kemenade pupius hardjono governmental and non governmental organizations have developed ways to certify institutional quality through evaluation or accreditation processes examples of these organizations include the european association for quality assurance in higher education enqa the quality assurance agency for higher education qaa the association to advance collegiate schools of business aacsb and the national institute of educational studies and research an sio teixeira inep many higher education institutions are applying for an iso certificate as a way to assure their quality lundquist ursin et al van kemenade et al but the most popular way to obtain evidence of quality in higher education programs is through external evaluation van kemenade et al external program evaluations are implemented with the goal of producing information that helps to better comprehend how activities processes and outcomes are contributing to the attainment of an organization s primary objectives therefore if properly used evaluations can potentially serve as an information system that can help educational institutions achieve their goals and correct possible deviations in their operations additionally according to the utilization focused evaluation literature educational programs could benefit from the evaluation report utilization because the ultimate purpose of evaluation is to improve programs and increase the quality of decisions made patton p the definition of evaluation use has been widely discussed in utilization focused evaluation theory among the many concepts of evaluation use that of cousins and leithwood perfectly fits the purpose of the present study this concept states that the mere psychological processing of evaluation results constitutes use without necessarily informing decisions dictating actions or changing thinking cousins leithwood p in an attempt to better distinguish the evaluation uses presented in the literature leviton and hughes summarized the categories for the most frequent uses described at that time and classified them into the current and broadly known types of use which include conceptual use instrumental use and persuasive use this nomenclature is generally accepted when describing the uses of evaluation findings alkin taut preskill caracelli the conceptual type of use also known as enlightenment braskamp owen lambert refers to improving the understanding of program aspects such as its participants its context or its outcomes through the evaluation the conceptual use is also related to developing new views of the program and identifying problems alkin braskamp henry mark the instrumental use perhaps the earliest type of use examined in the literature johnson p is related to the\n",
            "trends in international mathematics and science study\n",
            "tensor([   8, 1113,   13, 5002,  169,   30, 7625, 1356,  821,   46])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBOxEAxLYnOn"
      },
      "source": [
        "def jaccard(str1, str2): \n",
        "    a = set(str1.lower().split()) \n",
        "    b = set(str2.lower().split())\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
        "\n",
        "# def loss_func(pred, target):\n",
        "#     tmp = []\n",
        "#     token = token.from_pretrained(MODEL)\n",
        "#     for i in range(len(t)):\n",
        "        \n",
        "#         tt = np.where(t[i] != -100, t[i], 0)\n",
        "#         decode = token.decode(tt, skip_special_tokens=True, clean_up_tokenization_spaces=True)          \n",
        "#         tmp.append(jaccard(''.join(decode), target))\n",
        "#     return tmp\n",
        "\n",
        "def loss_func(pred, target, config):\n",
        "    tmp = []\n",
        "    MODEL = config['model']\n",
        "    tokenizer = token.from_pretrained(MODEL)\n",
        "    for i in range(len(pred)):\n",
        "        out_decode = tokenizer.decode(np.argmax(pred[i], axis = 1),\n",
        "                                  skip_special_tokens=True, \n",
        "                                  clean_up_tokenization_spaces=True)       \n",
        "        tmp.append(jaccard(''.join(out_decode), target[i]))\n",
        "    return tmp\n",
        "\n",
        "\n",
        "def train(model, data_loader, optimizer, config, scheduler = None):\n",
        "    model.train()\n",
        "    for _, txt in enumerate(data_loader):        \n",
        "        input_ids=txt['input_ids'].to(config['device'])\n",
        "        mask=txt['attention_mask'].to(config['device'])\n",
        "        labels = txt['labels'].to(config['device'])\n",
        "        optimizer.zero_grad()\n",
        "        loss, out = model(input_ids, mask, labels)\n",
        "        loss.backward()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "def valid(model, data_loader,config):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    asw = []\n",
        "    loss_2 = []\n",
        "    outs = []\n",
        "    for _, txt in enumerate(data_loader):\n",
        "        input_ids=txt['input_ids'].to(config['device'])\n",
        "        mask=txt['attention_mask'].to(config['device'])\n",
        "        labels = txt['labels'].to(config['device']) \n",
        "        answer=txt['answer']\n",
        "\n",
        "        loss, out = model(input_ids, mask, labels)\n",
        "        out = out.cpu().detach().numpy()\n",
        "        loss2 = loss_func(out, answer, config)\n",
        "        losses.append(loss.cpu().detach().numpy())\n",
        "        loss_2.append(loss2)\n",
        "        asw.append(answer)\n",
        "        outs.append(out)\n",
        "\n",
        "    return np.vstack(losses), np.vstack(asw), np.vstack(loss_2), np.vstack(outs)\n",
        "\n",
        "\n",
        "def run(config):\n",
        "    MODEL = config['model']\n",
        "\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Coleridge_Initiative/input/v6_data_qa.csv')\n",
        "    df_small = df.drop_duplicates(subset=['question']).reset_index(drop=True)\n",
        "    train_df, val_df = train_test_split(df_small.head(100), random_state = 13, test_size = 0.1)\n",
        "    tr = train_df.reset_index(drop=True)\n",
        "    vl = val_df.reset_index(drop=True)\n",
        "\n",
        "    tokenizer = token.from_pretrained(MODEL)\n",
        "\n",
        "    tr_dataset = CI_Dataset(tr,tokenizer,config)\n",
        "    vl_dataset = CI_Dataset(vl,tokenizer,config)\n",
        "\n",
        "    tr_loader = DataLoader(tr_dataset, batch_size = config['batch_size'], shuffle = True, num_workers = 4)\n",
        "    vl_loader = DataLoader(vl_dataset, batch_size = 1, num_workers = 4)\n",
        "\n",
        "    model = CI(config).to(config['device'])\n",
        "    optimizer = AdamW(model.parameters(), lr = config['learning_rate'])\n",
        "    bar =  tqdm(range(config['epoch']))\n",
        "    for e in bar:\n",
        "          \n",
        "        train(model, tr_loader, optimizer, config)\n",
        "        l, t, j, o = valid(model, vl_loader, config)\n",
        "        print('Loss:', np.mean(l))\n",
        "        bar.set_description(f'Jaccard Loss: {np.mean(j)}, Epoch: {e +1}')\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    return l,t, j, o"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ImU0XzvpHVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da7ee788-2ed0-429f-9dae-036d48e4e415"
      },
      "source": [
        "l, t, j, o = run(config)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Jaccard Loss: 0.35218253968253976, Epoch: 1:  50%|█████     | 1/2 [01:05<01:05, 65.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 8.616283\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard Loss: 0.35218253968253976, Epoch: 2: 100%|██████████| 2/2 [02:10<00:00, 65.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 8.616283\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46XZAvojYnIV"
      },
      "source": [
        "l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTYxVQ6YUjOw",
        "outputId": "86b31712-2860-4cf9-93d9-8ff3b106514e"
      },
      "source": [
        "jaccard('adni', 'andi')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6-uiCneRvUd",
        "outputId": "f7c5051c-c980-4c87-8940-10f3616ae552"
      },
      "source": [
        "np.argmax(o[1], axis = 1)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([32099,    13,  2913,   585,    11,   606,  6397,  6397,     3,\n",
              "           3,     3, 32099, 32099, 32099, 32099, 32099, 32099, 32099,\n",
              "       32099, 32099, 32099, 32099, 32099, 32099, 32099, 32099, 32099,\n",
              "       32099, 32099, 32099, 32099, 32099, 32099, 32099, 32099, 32099,\n",
              "       32099, 32099, 32099, 32099, 32099, 32099, 32099, 32099])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s1ZbcHsfQoWW",
        "outputId": "81f30d88-336f-4b6d-a159-2deba4205744"
      },
      "source": [
        "token.decode(np.argmax(o[-2], axis = 1), skip_special_tokens=True, clean_up_tokenization_spaces=True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'jd andi als      '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ1KqFumf7ya",
        "outputId": "f58cbeec-ee47-4b96-8c58-44453ee836ba"
      },
      "source": [
        "t"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['national assessment of education progress'],\n",
              "       ['survey of industrial research and development'],\n",
              "       ['early childhood longitudinal study'],\n",
              "       ['coastal change analysis program'],\n",
              "       ['trends in international mathematics and science study'],\n",
              "       ['nass census of agriculture'],\n",
              "       ['north american breeding bird survey'],\n",
              "       ['world ocean database'],\n",
              "       ['adni'],\n",
              "       ['coastal change analysis program']], dtype='<U53')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojSmkWm00J_I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}