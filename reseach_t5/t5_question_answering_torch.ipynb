{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 350,
     "status": "ok",
     "timestamp": 1623736167086,
     "user": {
      "displayName": "beifaa beifaa2",
      "photoUrl": "",
      "userId": "18300326005790323465"
     },
     "user_tz": -180
    },
    "id": "nLvuElwT90d1",
    "outputId": "e65e33d1-b6f1-4eb3-b272-426669ffe116"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8022,
     "status": "ok",
     "timestamp": 1623736175318,
     "user": {
      "displayName": "beifaa beifaa2",
      "photoUrl": "",
      "userId": "18300326005790323465"
     },
     "user_tz": -180
    },
    "id": "I_3UZqLw61B9",
    "outputId": "f7b13963-e810-4f6d-dee2-edb1d81ea7f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.41.1)\n",
      "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.18.2)\n",
      "Requirement already satisfied: torchmetrics>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.3.2)\n",
      "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.8.1+cu101)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (20.9)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2021.5.0)\n",
      "Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.4.1)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.19.5)\n",
      "Requirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.3.0)\n",
      "Requirement already satisfied: PyYAML<=5.4.1,>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch_lightning) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch_lightning) (2.4.7)\n",
      "Requirement already satisfied: requests; extra == \"http\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
      "Requirement already satisfied: aiohttp; extra == \"http\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.7.4.post0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.12.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.3.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.15.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.12.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.34.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (57.0.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.31.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.36.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (5.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.2.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (4.5.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (4.2.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.4.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.1.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.4.8)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_lightning\n",
    "!pip install transformers\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1Mu6OEa71I_"
   },
   "outputs": [],
   "source": [
    "!pip install wandb -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1217,
     "status": "ok",
     "timestamp": 1623736179171,
     "user": {
      "displayName": "beifaa beifaa2",
      "photoUrl": "",
      "userId": "18300326005790323465"
     },
     "user_tz": -180
    },
    "id": "nqC3b3SO8BeC",
    "outputId": "474c95a2-eccd-406d-91f3-00b82194cc66"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbeifa\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2219,
     "status": "ok",
     "timestamp": 1623736181388,
     "user": {
      "displayName": "beifaa beifaa2",
      "photoUrl": "",
      "userId": "18300326005790323465"
     },
     "user_tz": -180
    },
    "id": "bqh7j3n878Id",
    "outputId": "bb18cc93-ec62-4336-aa01-14158587f0a3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu101\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import os, glob, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import (T5ForConditionalGeneration,\n",
    "                          AdamW,\n",
    "                          T5TokenizerFast as token)\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "pl.seed_everything(13)\n",
    "print(torch.__version__)\n",
    "PATH = '/content/drive/MyDrive/Coleridge_Initiative/input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1623736181388,
     "user": {
      "displayName": "beifaa beifaa2",
      "photoUrl": "",
      "userId": "18300326005790323465"
     },
     "user_tz": -180
    },
    "id": "I33ZjK0CHwMi",
    "outputId": "151894a8-6f50-46aa-8341-c47b559d984d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 15 05:49:41 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   60C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHf1tD8WVPrf"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "executionInfo": {
     "elapsed": 3584,
     "status": "ok",
     "timestamp": 1623736184968,
     "user": {
      "displayName": "beifaa beifaa2",
      "photoUrl": "",
      "userId": "18300326005790323465"
     },
     "user_tz": -180
    },
    "id": "WY3lis9B9X5M",
    "outputId": "3888850a-89df-4da2-b7d3-d1eb43277b02"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "      <th>origin_text</th>\n",
       "      <th>origin_answer_start</th>\n",
       "      <th>origin_answer_end</th>\n",
       "      <th>len text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [question, text, answer, answer_start, answer_end, origin_text, origin_answer_start, origin_answer_end, len text, id]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/Coleridge_Initiative/input/v6_data_qa.csv')\n",
    "df[df.answer.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "executionInfo": {
     "elapsed": 2189,
     "status": "ok",
     "timestamp": 1623736187150,
     "user": {
      "displayName": "beifaa beifaa2",
      "photoUrl": "",
      "userId": "18300326005790323465"
     },
     "user_tz": -180
    },
    "id": "skTdDeA19iuh",
    "outputId": "66294bee-f788-4a2d-fea9-6c2264e409a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.32<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">T5_t5-small_question_LR:0.0008_BATCH:3_FRAC_DATA:0.8</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/beifa/ci\" target=\"_blank\">https://wandb.ai/beifa/ci</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/beifa/ci/runs/3snh6ps7\" target=\"_blank\">https://wandb.ai/beifa/ci/runs/3snh6ps7</a><br/>\n",
       "                Run data is saved locally in <code>/content/wandb/run-20210615_054944-3snh6ps7</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wandb.init(project=\"ci\", config={\n",
    "#     \"learning_rate\": 0.0001,\n",
    "#     \"architecture\": \"T5\",\n",
    "#     'model': 't5-base',\n",
    "#     \"dataset\": \"Coleridge Initiative \",\n",
    "#     'tex_max_len': 396,\n",
    "#     'asw_max_len': 44,\n",
    "#     'batch_size' : BATCH_SIZE,\n",
    "#     'epoch':N_EPOCHS\n",
    "# })\n",
    "# config = wandb.config\n",
    "\n",
    "BATCH = 3\n",
    "EPOCHS = 7\n",
    "FRAC = 0.8 # all data mem error\n",
    "\n",
    "config={\n",
    "    'type_model': 'question',\n",
    "    \"learning_rate\": 0.0008,\n",
    "    \"architecture\": \"T5\",\n",
    "    'model': 't5-small', #'t5-base', # t5-small\n",
    "    \"dataset\": \"Coleridge Initiative \",\n",
    "    'tex_max_len': 524,#396,\n",
    "    'asw_max_len': 18,\n",
    "    'batch_size' : BATCH,\n",
    "    'epoch':EPOCHS,\n",
    "    'device': 'cuda'\n",
    "}\n",
    "\n",
    "wandb.init(project=\"ci\",\n",
    "           config=config,\n",
    "           name =  f\"{config['architecture']}_{config['model']}_{config['type_model']}\"+\\\n",
    "                   f\"_LR:{config['learning_rate']}_BATCH:{BATCH}_FRAC_DATA:{FRAC}\"\n",
    "           )\n",
    "config_w = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ceo8GpbU_Uuo"
   },
   "outputs": [],
   "source": [
    "class CI_Dataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        tokenizer: token,\n",
    "        config\n",
    "    ):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.tex_max_len = config['tex_max_len']\n",
    "        self.asw_max_len = config['asw_max_len']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index:int):\n",
    "        txt = self.data.iloc[index]\n",
    "\n",
    "        encode_txt = token(\n",
    "            txt['question'],\n",
    "            txt['text'],\n",
    "            max_length = self.tex_max_len, \n",
    "            padding= 'max_length',\n",
    "            truncation = 'only_second',\n",
    "            return_attention_mask = True,\n",
    "            add_special_tokens =True,\n",
    "            return_tensors = 'pt'\n",
    "            )\n",
    "        \n",
    "        encode_asw = token( \n",
    "            txt['answer'],\n",
    "            max_length = self.asw_max_len,\n",
    "            padding= 'max_length',\n",
    "            truncation = True,\n",
    "            return_attention_mask = True,\n",
    "            add_special_tokens =True,\n",
    "            return_tensors = 'pt'\n",
    "            )\n",
    "        labels = encode_asw['input_ids']\n",
    "        labels[labels == 0] = -100\n",
    "\n",
    "        return dict(\n",
    "            question=txt['question'],\n",
    "            text=txt['text'],\n",
    "            answer=txt['answer'],\n",
    "            input_ids=encode_txt['input_ids'].flatten(),\n",
    "            attention_mask=encode_txt['attention_mask'].flatten(),\n",
    "            labels = labels.flatten()\n",
    "            )\n",
    "        \n",
    "class CI(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()     \n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(config['model'], return_dict = True)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels):\n",
    "        out = self.model(input_ids = input_ids,\n",
    "                    attention_mask = attention_mask,\n",
    "                    labels = labels\n",
    "                    )\n",
    "        return out.loss, out.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1838,
     "status": "ok",
     "timestamp": 1623736188984,
     "user": {
      "displayName": "beifaa beifaa2",
      "photoUrl": "",
      "userId": "18300326005790323465"
     },
     "user_tz": -180
    },
    "id": "mBb9cgbwAC76",
    "outputId": "df4eeccc-86ff-4116-daea-a7b68c821d0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the impact of evaluation use on accounting programs performance an exploratory study\n",
      "the quality of educational programs has been an object of debate and research around the world initiatives such as the program for international student assessment pisa and the trends in international mathematics and science study timss show that international organizations such as the organization for economic co operation and development oecd and the international association for the evaluation of educational achievement iea are trying to verify whether schools are adequately preparing their students by comparing their performances aiming to highlight the strengths and weaknesses among the educational systems of different countries higher education has also been the object of quality evaluations around the world ursin huusko aittola kiviniemi muhonen van kemenade pupius hardjono governmental and non governmental organizations have developed ways to certify institutional quality through evaluation or accreditation processes examples of these organizations include the european association for quality assurance in higher education enqa the quality assurance agency for higher education qaa the association to advance collegiate schools of business aacsb and the national institute of educational studies and research an sio teixeira inep many higher education institutions are applying for an iso certificate as a way to assure their quality lundquist ursin et al van kemenade et al but the most popular way to obtain evidence of quality in higher education programs is through external evaluation van kemenade et al external program evaluations are implemented with the goal of producing information that helps to better comprehend how activities processes and outcomes are contributing to the attainment of an organization s primary objectives therefore if properly used evaluations can potentially serve as an information system that can help educational institutions achieve their goals and correct possible deviations in their operations additionally according to the utilization focused evaluation literature educational programs could benefit from the evaluation report utilization because the ultimate purpose of evaluation is to improve programs and increase the quality of decisions made patton p the definition of evaluation use has been widely discussed in utilization focused evaluation theory among the many concepts of evaluation use that of cousins and leithwood perfectly fits the purpose of the present study this concept states that the mere psychological processing of evaluation results constitutes use without necessarily informing decisions dictating actions or changing thinking cousins leithwood p in an attempt to better distinguish the evaluation uses presented in the literature leviton and hughes summarized the categories for the most frequent uses described at that time and classified them into the current and broadly known types of use which include conceptual use instrumental use and persuasive use this nomenclature is generally accepted when describing the uses of evaluation findings alkin taut preskill caracelli the conceptual type of use also known as enlightenment braskamp owen lambert refers to improving the understanding of program aspects such as its participants its context or its outcomes through the evaluation the conceptual use is also related to developing new views of the program and identifying problems alkin braskamp henry mark the instrumental use perhaps the earliest type of use examined in the literature johnson p is related to the\n",
      "trends in international mathematics and science study\n",
      "tensor([   8, 1113,   13, 5002,  169,   30, 7625, 1356,  821,   46])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "MODEL = config['model']\n",
    "token = token.from_pretrained(MODEL)\n",
    "exampe_dataset = CI_Dataset(df, token, config)\n",
    "\n",
    "for data in exampe_dataset:\n",
    "    print(data['question'])\n",
    "    print(data['text'])\n",
    "    print(data['answer'])\n",
    "\n",
    "    print(data['input_ids'][:10])\n",
    "    print(data['attention_mask'][:10])    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBOxEAxLYnOn"
   },
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "def make_current_date()->str:\n",
    "    x = datetime.datetime.now()\n",
    "    x = str(x.date())\n",
    "    return x.replace('-', '_')\n",
    "\n",
    "\n",
    "# def loss_func(pred, target):\n",
    "#     tmp = []\n",
    "#     token = token.from_pretrained(MODEL)\n",
    "#     for i in range(len(t)):\n",
    "        \n",
    "#         tt = np.where(t[i] != -100, t[i], 0)\n",
    "#         decode = token.decode(tt, skip_special_tokens=True, clean_up_tokenization_spaces=True)          \n",
    "#         tmp.append(jaccard(''.join(decode), target))\n",
    "#     return tmp\n",
    "\n",
    "def loss_func(pred, target, config):\n",
    "    tmp = []\n",
    "    MODEL = config['model']\n",
    "    tokenizer = token.from_pretrained(MODEL)\n",
    "    for i in range(len(pred)):\n",
    "        out_decode = tokenizer.decode(np.argmax(pred[i], axis = 1),\n",
    "                                  skip_special_tokens=True, \n",
    "                                  clean_up_tokenization_spaces=True)       \n",
    "        tmp.append(jaccard(''.join(out_decode), target[i]))\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def train(model, data_loader, optimizer, config, scheduler = None):\n",
    "    model.train()\n",
    "    o = []\n",
    "    for _, txt in enumerate(data_loader):        \n",
    "        input_ids=txt['input_ids'].to(config['device'])\n",
    "        mask=txt['attention_mask'].to(config['device'])\n",
    "        labels = txt['labels'].to(config['device'])\n",
    "        optimizer.zero_grad()\n",
    "        loss, out = model(input_ids, mask, labels)\n",
    "        # print(loss)\n",
    "        # print('----')    \n",
    "        # loss = model(input_ids, mask, labels)\n",
    "        o.append(loss.cpu().detach().numpy())        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "    return np.mean(o)\n",
    "\n",
    "def valid(model, data_loader,config):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    asw = []\n",
    "    loss_2 = []\n",
    "    outs = []\n",
    "    for _, txt in enumerate(data_loader):\n",
    "        input_ids=txt['input_ids'].to(config['device'])\n",
    "        mask=txt['attention_mask'].to(config['device'])\n",
    "        labels = txt['labels'].to(config['device']) \n",
    "        answer=txt['answer']\n",
    "\n",
    "        loss, out = model(input_ids, mask, labels)\n",
    "        out = out.cpu().detach().numpy()\n",
    "        loss2 = loss_func(out, answer, config)\n",
    "        losses.append(loss.cpu().detach().numpy())\n",
    "        loss_2.append(loss2)\n",
    "        asw.append(answer)\n",
    "        outs.append(out)\n",
    "    # print(losses)\n",
    "    # print(loss_2)\n",
    "    return losses, np.vstack(asw), loss_2, np.vstack(outs)\n",
    "\n",
    "\n",
    "def run(config):\n",
    "    MODEL = config['model']\n",
    "\n",
    "    df = pd.read_csv('/content/drive/MyDrive/Coleridge_Initiative/input/v6_data_qa.csv')\n",
    "    df_small = df.drop_duplicates(subset=['question']).sample(frac = FRAC, random_state = 13).reset_index(drop=True)\n",
    "    train_df, val_df = train_test_split(df_small, random_state = 13, test_size = 0.1)\n",
    "    tr = train_df.reset_index(drop=True)\n",
    "    vl = val_df.reset_index(drop=True)\n",
    "\n",
    "    tokenizer = token.from_pretrained(MODEL)\n",
    "\n",
    "    tr_dataset = CI_Dataset(tr,tokenizer,config)\n",
    "    vl_dataset = CI_Dataset(vl,tokenizer,config)\n",
    "\n",
    "    tr_loader = DataLoader(tr_dataset, batch_size = config['batch_size'], shuffle = True, num_workers = 4)\n",
    "    vl_loader = DataLoader(vl_dataset, batch_size = 1, num_workers = 4)\n",
    "\n",
    "    model = CI(config).to(config['device'])\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr = config['learning_rate'])\n",
    "    bar =  tqdm(range(config['epoch']))\n",
    "    wandb.watch(model) \n",
    "    best_jaccard = 0\n",
    "    for e in bar:          \n",
    "        tl = train(model, tr_loader, optimizer, config)      \n",
    "        l, _, j, _ = valid(model, vl_loader, config)    \n",
    "        jaccard = np.mean(j)\n",
    "        bar.set_description(f'Valid loss: {np.mean(l)}, Jaccard Loss: {jaccard}, Epoch: {e + 1}')\n",
    "        wandb.log(\n",
    "                  {'epoch': e,\n",
    "                   \"tr_loss\": np.mean(tl), \n",
    "                   'vl loss': np.mean(l),\n",
    "                   'jaccad': jaccard\n",
    "                \n",
    "                   }\n",
    "                  )\n",
    "        \n",
    "        if jaccard > best_jaccard:\n",
    "            print('\\n')\n",
    "            print(f'Best jaccard save: {jaccard}, prev: {best_jaccard}')\n",
    "            torch.save(model.state_dict(), f'/content/drive/MyDrive/Coleridge_Initiative/model/model_{MODEL}_{EPOCHS}_{BATCH}_{FRAC}_{make_current_date()}.pth')\n",
    "            best_jaccard = jaccard\n",
    "\n",
    "    # https://pytorch.org/tutorials/beginner/saving_loading_models.html    \n",
    "    # torch.save(model.state_dict(), f'/content/drive/MyDrive/Coleridge_Initiative/model/model_{MODEL}_{EPOCHS}_{BATCH}_{FRAC}_{make_current_date()}.pth')\n",
    "    wandb.finish()\n",
    "    torch.cuda.empty_cache()    \n",
    "    # return l,t, j, o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1623736189336,
     "user": {
      "displayName": "beifaa beifaa2",
      "photoUrl": "",
      "userId": "18300326005790323465"
     },
     "user_tz": -180
    },
    "id": "6tzZX53_IIy1",
    "outputId": "7527b7a7-fa4c-4514-f7e8-87e1347b1c88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11122, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset=['question']).sample(frac = 0.8, random_state = 13).reset_index(drop=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ImU0XzvpHVU",
    "outputId": "8285058e-35af-4c16-adb2-f0f8e7c97434"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "Valid loss: 0.4280939996242523, Jaccard Loss: 0.7956471382149201, Epoch: 1:   0%|          | 0/7 [38:11<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best jaccard save: 0.7956471382149201, prev: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.38686683773994446, Jaccard Loss: 0.817383141554697, Epoch: 3:  29%|██▊       | 2/7 [1:56:26<3:11:34, 2298.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best jaccard save: 0.817383141554697, prev: 0.7956471382149201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.4140581786632538, Jaccard Loss: 0.8264610875796858, Epoch: 4:  43%|████▎     | 3/7 [2:35:34<2:34:54, 2323.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best jaccard save: 0.8264610875796858, prev: 0.817383141554697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.45526617765426636, Jaccard Loss: 0.8156114132331034, Epoch: 6:  86%|████████▌ | 6/7 [3:54:50<39:13, 2353.78s/it]  "
     ]
    }
   ],
   "source": [
    "# l, t, j, o =\n",
    "run(config)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "t5_question_answering_torch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
